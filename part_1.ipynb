{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() and use_gpu else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from torchvision import transforms, models, datasets\n",
    "import torch \n",
    "from torch.utils.data import DataLoader, Subset, random_split, ConcatDataset\n",
    "import numpy as np \n",
    "import random \n",
    "from os.path import exists\n",
    "import os \n",
    "from typing import List, Dict, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "def get_oxford_splits(\n",
    "    batch_size: int,\n",
    "    data_loader_seed: int = 111, \n",
    "    pin_memory: bool = True,\n",
    "    num_workers: int = 2,\n",
    "    ): \n",
    "    K = 5\n",
    "    num_support = 80\n",
    "    num_query = 20 \n",
    "\n",
    "    def seed_worker(worker_id=None):\n",
    "        # worker_seed = torch.initial_seed() % 2 ** 32\n",
    "        np.random.seed(data_loader_seed)\n",
    "        random.seed(data_loader_seed)\n",
    "    \n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(data_loader_seed)\n",
    "\n",
    "    support_classes = list(np.arange(num_support))\n",
    "    query_classes = list(np.arange(num_query) + num_support)\n",
    "\n",
    "    img_dim = 64\n",
    "\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((img_dim, img_dim)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.Resize((img_dim, img_dim)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
    "    validation_transforms = transforms.Compose([\n",
    "        transforms.Resize((img_dim, img_dim)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
    "    \n",
    "    data_path = f'/content/data'\n",
    "\n",
    "    train_ds_full = datasets.Flowers102(root=data_path, split=\"train\", download=True, transform=train_transforms)\n",
    "    val_ds_full = datasets.Flowers102(root=data_path, split=\"val\", download=True, transform=validation_transforms)\n",
    "    test_ds_full = datasets.Flowers102(root=data_path, split=\"test\", download=True, transform=test_transforms)\n",
    "\n",
    "    train_indxs_support = torch.where(torch.isin(torch.tensor(train_ds_full._labels), torch.asarray(support_classes)))[0]\n",
    "    val_indxs_support = torch.where(torch.isin(torch.tensor(val_ds_full._labels), torch.asarray(support_classes)))[0]\n",
    "    test_indxs_support = torch.where(torch.isin(torch.tensor(test_ds_full._labels), torch.asarray(support_classes)))[0]\n",
    "    \n",
    "    train_ds_subset_support = torch.utils.data.Subset(train_ds_full, train_indxs_support)\n",
    "    val_ds_subset_support = torch.utils.data.Subset(val_ds_full, val_indxs_support)\n",
    "    test_ds_subset_support = torch.utils.data.Subset(test_ds_full, test_indxs_support)\n",
    "\n",
    "    merged_dataset = ConcatDataset([train_ds_subset_support, val_ds_subset_support, test_ds_subset_support])\n",
    "    ### A, B\n",
    "    train_ds_support, test_ds_support = torch.utils.data.random_split(merged_dataset, [0.75, 0.25], generator=torch.Generator().manual_seed(42))\n",
    "    ### \n",
    "\n",
    "    train_indxs_query = torch.where(torch.isin(torch.tensor(train_ds_full._labels), torch.asarray(query_classes)))[0]\n",
    "    N = 10 \n",
    "    starting_indices = np.arange(0, len(train_indxs_query), N)\n",
    "    train_indxs_query = np.hstack([train_indxs_query[i:i+K] for i in starting_indices if i + K <= len(train_indxs_query)])\n",
    "    ### C\n",
    "    train_ds_query = torch.utils.data.Subset(train_ds_full, train_indxs_query) \n",
    "    ###\n",
    "\n",
    "    val_indxs_query = torch.where(torch.isin(torch.tensor(val_ds_full._labels), torch.asarray(query_classes)))[0]\n",
    "    test_indxs_query = torch.where(torch.isin(torch.tensor(test_ds_full._labels), torch.asarray(query_classes)))[0]\n",
    "    val_ds_subset_query = torch.utils.data.Subset(val_ds_full, val_indxs_query)\n",
    "    test_ds_subset_query = torch.utils.data.Subset(test_ds_full, test_indxs_query)\n",
    "    \n",
    "    test_ds_query_full = ConcatDataset([val_ds_subset_query, test_ds_subset_query])\n",
    "    ### D \n",
    "    _, test_ds_query = torch.utils.data.random_split(test_ds_query_full, [0.7, 0.3], generator=torch.Generator().manual_seed(42))\n",
    "    ###\n",
    "    \n",
    "    ### E \n",
    "    test_all = ConcatDataset([test_ds_query, test_ds_support])\n",
    "\n",
    "\n",
    "    A_train_dl = DataLoader(\n",
    "        train_ds_support,\n",
    "        batch_size = batch_size, \n",
    "        shuffle=True, \n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g,\n",
    "        drop_last=False,\n",
    "        pin_memory=pin_memory,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    A_test_dl = DataLoader(\n",
    "        test_ds_support,\n",
    "        batch_size = batch_size, \n",
    "        shuffle=True, \n",
    "        worker_init_fn=seed_worker(data_loader_seed),\n",
    "        generator=g,\n",
    "        drop_last=False,\n",
    "        pin_memory=pin_memory,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    B_train_dl = DataLoader(\n",
    "        train_ds_query,\n",
    "        batch_size = batch_size, \n",
    "        shuffle=True, \n",
    "        worker_init_fn=seed_worker(data_loader_seed),\n",
    "        generator=g,\n",
    "        drop_last=False,\n",
    "        pin_memory=pin_memory,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    B_test_dl = DataLoader(\n",
    "        test_ds_query,\n",
    "        batch_size = batch_size, \n",
    "        shuffle=True, \n",
    "        worker_init_fn=seed_worker(data_loader_seed),\n",
    "        generator=g,\n",
    "        drop_last=False,\n",
    "        pin_memory=pin_memory,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    test_all = DataLoader(\n",
    "        test_all,\n",
    "        batch_size = batch_size, \n",
    "        shuffle=True, \n",
    "        worker_init_fn=seed_worker(data_loader_seed),\n",
    "        generator=g,\n",
    "        drop_last=False,\n",
    "        pin_memory=pin_memory,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    return A_train_dl, A_test_dl, B_train_dl, B_test_dl, test_all\n",
    "\n",
    "\n",
    "def make_dir(dir_name: str):\n",
    "    \"\"\"\n",
    "    creates directory \"dir_name\" if it doesn't exists\n",
    "    \"\"\"\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "\n",
    "def custom_plot_training_stats(\n",
    "        acc_hist, \n",
    "        loss_hist, \n",
    "        phase_list, \n",
    "        title: str, \n",
    "        dir: str, \n",
    "        name: str = 'acc_loss'): \n",
    "    fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize=[14, 6], dpi=100)\n",
    "\n",
    "    for phase in phase_list: \n",
    "        lowest_loss_x = np.argmin(np.array(loss_hist[phase]))\n",
    "        lowest_loss_y = loss_hist[phase][lowest_loss_x]\n",
    "        \n",
    "        ax1.annotate(\"{:.4f}\".format(lowest_loss_y), [lowest_loss_x, lowest_loss_y])\n",
    "        ax1.plot(loss_hist[phase], '-x', label=f'{phase} loss', markevery = [lowest_loss_x])\n",
    "\n",
    "        ax1.set_xlabel(xlabel='epochs')\n",
    "        ax1.set_ylabel(ylabel='loss')\n",
    "\n",
    "        ax1.grid(color = 'green', linestyle = '--', linewidth = 0.5, alpha=0.75)\n",
    "        ax1.legend()\n",
    "        ax1.label_outer()\n",
    "\n",
    "    # acc: \n",
    "    for phase in phase_list:\n",
    "        highest_acc_x = np.argmax(np.array(acc_hist[phase]))\n",
    "        highest_acc_y = acc_hist[phase][highest_acc_x]\n",
    "        \n",
    "        ax2.annotate(\"{:.4f}\".format(highest_acc_y), [highest_acc_x, highest_acc_y])\n",
    "        ax2.plot(acc_hist[phase], '-x', label=f'{phase} acc', markevery = [highest_acc_x])\n",
    "\n",
    "        ax2.set_xlabel(xlabel='epochs')\n",
    "        ax2.set_ylabel(ylabel='acc')\n",
    "\n",
    "        ax2.grid(color = 'green', linestyle = '--', linewidth = 0.5, alpha=0.75)\n",
    "        ax2.legend()\n",
    "        #ax2.label_outer()\n",
    "\n",
    "    fig.suptitle(f'{title}')\n",
    "\n",
    "    make_dir(dir)\n",
    "    plt.savefig(f'{dir}/{name}.jpg')\n",
    "    plt.clf()\n",
    "\n",
    "def plot_conf(labels, preds, title, dir_, name):\n",
    "    \"\"\"\n",
    "    labels: an [N, ] array containing true labels for N samples\n",
    "    preds: an [N, ] array containing predications for N samples\n",
    "    \n",
    "    saves confusion matrix plot of the given prediction and true labels in 'dir_/name.jpg' \n",
    "    \"\"\"\n",
    "\n",
    "    conf = confusion_matrix(labels, preds)\n",
    "\n",
    "    plt.clf()\n",
    "    cm = conf.astype('float') / conf.sum(axis=1)[:, np.newaxis]\n",
    "    cmap = sns.light_palette(\"navy\", as_cmap=True)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    sns.heatmap(cm, annot=False, cmap=cmap, fmt=\".2f\", cbar=False)\n",
    "    plt.title(f'{title}')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    make_dir(dir_)\n",
    "    plt.savefig(f'{dir_}/{name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_train_dl, A_test_dl, B_train_dl, B_test_dl, test_all = get_oxford_splits(\n",
    "    batch_size=128,\n",
    "    data_loader_seed=111,\n",
    "    pin_memory=False,\n",
    "    num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4617, 1538, 100, 518)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(A_train_dl.dataset), len(A_test_dl.dataset), len(B_train_dl.dataset), len(B_test_dl.dataset), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(A_train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data index:  0\n",
      "input:  torch.Size([3, 64, 64]) , type of input:  <class 'torch.Tensor'>\n",
      "target:  46 , type of target:  <class 'int'>\n",
      "data index:  1\n",
      "input:  torch.Size([3, 64, 64]) , type of input:  <class 'torch.Tensor'>\n",
      "target:  54 , type of target:  <class 'int'>\n",
      "data index:  2\n",
      "input:  torch.Size([3, 64, 64]) , type of input:  <class 'torch.Tensor'>\n",
      "target:  17 , type of target:  <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "for data_indx, (input, target) in enumerate(A_train_dl.dataset):\n",
    "    if data_indx < 3:\n",
    "        print('data index: ', data_indx)\n",
    "        print('input: ', input.shape, ', type of input: ', type(input))\n",
    "        print('target: ', target, ', type of target: ', type(target))\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images of one batch:  torch.Size([128, 3, 64, 64])\n",
      "torch.Size([128])\n",
      "(tensor([80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97,\n",
      "        98, 99]), tensor([10,  8,  7, 10,  2,  5,  7,  7, 13,  3,  6,  3,  3, 12, 10,  4,  3,  5,\n",
      "         6,  4]))\n"
     ]
    }
   ],
   "source": [
    "for batch_indx, (images, labels) in enumerate(B_test_dl):\n",
    "    if batch_indx == 0:\n",
    "        print('images of one batch: ', images.shape)\n",
    "        print(labels.shape)\n",
    "        print(torch.unique(labels, return_counts=True))\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images of one batch:  torch.Size([128, 3, 64, 64])\n",
      "torch.Size([128])\n",
      "(tensor([ 0,  2,  3,  4,  7, 10, 11, 12, 13, 14, 15, 16, 17, 21, 22, 26, 28, 29,\n",
      "        30, 31, 32, 33, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "        51, 52, 55, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
      "        73, 74, 75, 76, 77, 78]), tensor([1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 3, 2, 2, 3, 1, 4, 2, 1, 1, 1, 1, 1,\n",
      "        1, 2, 3, 2, 1, 2, 3, 2, 3, 3, 3, 3, 2, 3, 2, 4, 2, 1, 4, 1, 3, 4, 1, 2,\n",
      "        1, 1, 3, 1, 2, 2, 3, 7, 1, 6, 1, 2]))\n",
      "(tensor([ 1,  3,  5,  6,  7,  9, 10, 11, 12, 13, 14, 17, 19, 20, 21, 22, 23, 25,\n",
      "        26, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,\n",
      "        48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 64, 65, 66, 68,\n",
      "        69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]), tensor([1, 3, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 3, 3, 1, 3, 1, 3, 5, 1, 3, 1,\n",
      "        3, 1, 1, 5, 3, 2, 2, 2, 2, 5, 2, 1, 1, 1, 6, 3, 1, 3, 1, 2, 1, 3, 1, 4,\n",
      "        1, 2, 2, 1, 1, 3, 1, 2, 2, 4, 1, 1, 1, 3, 2, 1, 1]))\n",
      "(tensor([ 1,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23,\n",
      "        26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45,\n",
      "        46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 67, 68, 70,\n",
      "        71, 72, 73, 74, 75, 76, 77, 79]), tensor([2, 2, 5, 3, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 3,\n",
      "        1, 1, 1, 4, 1, 1, 3, 1, 1, 5, 1, 7, 2, 4, 1, 3, 2, 3, 1, 2, 1, 1, 3, 2,\n",
      "        3, 1, 2, 1, 2, 3, 2, 1, 2, 2, 2, 7, 4, 6]))\n",
      "(tensor([ 1,  2,  4,  6,  7,  8, 11, 13, 15, 16, 17, 18, 19, 21, 22, 24, 25, 27,\n",
      "        28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 49, 50,\n",
      "        51, 52, 54, 55, 56, 57, 58, 59, 60, 62, 64, 66, 67, 68, 69, 70, 71, 72,\n",
      "        73, 74, 75, 76, 77, 78, 79]), tensor([1, 1, 2, 1, 1, 2, 1, 2, 1, 4, 2, 2, 1, 2, 1, 1, 1, 3, 2, 2, 1, 1, 2, 2,\n",
      "        2, 2, 1, 3, 4, 2, 4, 5, 2, 2, 5, 7, 3, 1, 1, 4, 3, 2, 1, 3, 2, 1, 4, 1,\n",
      "        1, 1, 4, 1, 1, 1, 4, 2, 1, 3, 1, 2, 2]))\n",
      "(tensor([ 5,  7,  8, 10, 11, 12, 13, 15, 16, 17, 19, 21, 22, 23, 24, 25, 27, 28,\n",
      "        29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 43, 45, 48, 50, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 63, 64, 65, 67, 68, 69, 70, 71, 72, 74, 75, 76,\n",
      "        77, 79]), tensor([1, 3, 2, 2, 3, 1, 2, 1, 3, 2, 2, 2, 4, 1, 1, 4, 1, 2, 1, 1, 1, 4, 1, 3,\n",
      "        6, 1, 2, 3, 2, 2, 5, 2, 1, 6, 1, 3, 2, 4, 1, 2, 3, 3, 1, 2, 1, 1, 1, 1,\n",
      "        4, 1, 3, 4, 3, 5, 2, 2]))\n",
      "(tensor([ 0,  2,  4,  5,  8, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 24, 25,\n",
      "        26, 27, 28, 29, 30, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48,\n",
      "        49, 50, 52, 54, 55, 57, 59, 60, 62, 63, 64, 65, 66, 68, 70, 71, 72, 73,\n",
      "        74, 75, 76, 77, 78, 79]), tensor([2, 2, 3, 1, 3, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 4, 1, 1,\n",
      "        1, 2, 1, 5, 2, 3, 5, 2, 6, 1, 1, 1, 1, 4, 3, 2, 1, 2, 4, 4, 1, 3, 4, 2,\n",
      "        1, 3, 1, 1, 3, 4, 2, 2, 4, 1, 1, 4]))\n",
      "(tensor([ 0,  1,  3,  6,  7,  8,  9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 22,\n",
      "        23, 26, 27, 28, 29, 30, 32, 34, 35, 37, 38, 40, 41, 42, 43, 45, 46, 48,\n",
      "        49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 63, 64, 66, 67, 68, 69, 70, 72,\n",
      "        73, 74, 75, 76, 77, 79]), tensor([2, 1, 2, 2, 1, 1, 1, 2, 1, 3, 1, 1, 2, 1, 1, 1, 1, 7, 1, 2, 1, 1, 4, 4,\n",
      "        1, 3, 1, 2, 2, 3, 4, 2, 3, 3, 1, 1, 1, 9, 2, 3, 1, 4, 1, 1, 2, 2, 2, 3,\n",
      "        3, 2, 1, 2, 2, 3, 2, 2, 1, 6, 1, 2]))\n",
      "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21,\n",
      "        22, 23, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43,\n",
      "        45, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66,\n",
      "        67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 79]), tensor([1, 1, 1, 2, 1, 2, 5, 3, 2, 4, 2, 3, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1,\n",
      "        2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 2, 2, 1, 4, 3, 2, 2, 3, 3, 3, 1, 3,\n",
      "        2, 2, 1, 1, 1, 1, 1, 1, 2, 3, 2, 3, 2, 1, 7, 5, 3]))\n",
      "(tensor([ 0,  1,  2,  4,  6,  8,  9, 10, 11, 13, 14, 16, 19, 21, 23, 24, 25, 26,\n",
      "        27, 28, 29, 31, 33, 34, 36, 37, 38, 39, 40, 42, 45, 46, 47, 48, 49, 50,\n",
      "        51, 52, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 72, 73, 74, 76, 77,\n",
      "        79]), tensor([2, 2, 2, 4, 2, 3, 2, 1, 2, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 3,\n",
      "        2, 1, 1, 2, 3, 3, 5, 1, 1, 1, 3, 5, 5, 2, 1, 1, 2, 6, 5, 1, 2, 2, 5, 2,\n",
      "        2, 2, 1, 2, 7, 5, 3]))\n",
      "(tensor([ 1,  3,  4,  5,  8,  9, 10, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 25,\n",
      "        26, 27, 28, 31, 32, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50,\n",
      "        51, 52, 55, 56, 57, 58, 59, 61, 62, 66, 67, 68, 69, 70, 71, 72, 73, 74,\n",
      "        75, 76, 77, 78, 79]), tensor([2, 1, 2, 3, 2, 2, 1, 1, 2, 2, 4, 3, 2, 1, 2, 1, 1, 1, 2, 1, 4, 1, 1, 1,\n",
      "        3, 1, 3, 1, 3, 2, 1, 5, 2, 2, 3, 3, 1, 3, 3, 3, 2, 2, 5, 2, 2, 1, 2, 1,\n",
      "        1, 4, 1, 5, 1, 2, 1, 6, 3, 3, 2]))\n",
      "(tensor([ 1,  3,  4,  5,  8, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22, 25, 28, 30,\n",
      "        31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 48, 49, 50, 51,\n",
      "        52, 53, 54, 55, 57, 58, 61, 62, 64, 67, 68, 69, 70, 71, 72, 73, 74, 75,\n",
      "        76, 77, 79]), tensor([2, 2, 1, 2, 2, 3, 1, 2, 1, 4, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2,\n",
      "        3, 1, 1, 3, 4, 2, 3, 5, 1, 2, 7, 2, 4, 2, 2, 2, 2, 1, 2, 2, 3, 2, 2, 3,\n",
      "        3, 1, 4, 4, 2, 3, 6, 2, 2]))\n",
      "(tensor([ 0,  2,  4,  7,  8,  9, 10, 11, 12, 14, 17, 18, 19, 20, 21, 22, 23, 24,\n",
      "        26, 27, 28, 30, 31, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 51,\n",
      "        52, 53, 55, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73,\n",
      "        74, 75, 76, 77, 78, 79]), tensor([2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 3, 1, 1, 1, 2, 1, 1, 1, 1,\n",
      "        1, 3, 2, 1, 2, 3, 1, 4, 1, 1, 3, 1, 2, 2, 5, 6, 1, 4, 1, 2, 1, 2, 4, 1,\n",
      "        1, 2, 1, 1, 3, 4, 3, 4, 7, 3, 3, 4]))\n",
      "(tensor([27, 65]), tensor([1, 1]))\n"
     ]
    }
   ],
   "source": [
    "for batch_indx, (images, labels) in enumerate(A_test_dl):\n",
    "    if batch_indx == 0:\n",
    "        print('images of one batch: ', images.shape)\n",
    "        print(labels.shape)\n",
    "        print(torch.unique(labels, return_counts=True))\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=80):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 96, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(96)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(96, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc = nn.Linear(256*4*4, num_classes)\n",
    "\n",
    "    def forward(self, inputs, debug=False):\n",
    "        self.flatten = nn.Flatten()\n",
    "        # conv 1\n",
    "        conv1 = self.conv1(inputs)\n",
    "        bn1 = self.bn1(conv1)\n",
    "        relu1 = self.relu1(bn1)\n",
    "\n",
    "        # conv 2\n",
    "        conv2_1 = self.conv2(relu1)\n",
    "        bn2_1 = self.bn2(conv2_1)\n",
    "        relu2_1 = self.relu2(bn2_1)\n",
    "\n",
    "        conv2_2 = self.conv2(relu2_1)\n",
    "        bn2_2 = self.bn2(conv2_2)\n",
    "        relu2_2 = self.relu2(bn2_2)\n",
    "\n",
    "        conv2_3 = self.conv2(relu2_2)\n",
    "        bn2_3 = self.bn2(conv2_3)\n",
    "        relu2_3 = self.relu2(bn2_3)\n",
    "\n",
    "        conv2_4 = self.conv2(relu2_3)\n",
    "        bn2_4 = self.bn2(conv2_4)\n",
    "        relu2_4 = self.relu2(bn2_4)\n",
    "\n",
    "        # pool 1\n",
    "        pool1 = self.pool1(relu2_4)\n",
    "\n",
    "        # conv 3\n",
    "        conv3_1 = self.conv3(pool1)\n",
    "        bn3_1 = self.bn3(conv3_1)\n",
    "        relu3_1 = self.relu3(bn3_1)\n",
    "\n",
    "        conv3_2 = self.conv3(relu3_1)\n",
    "        bn3_2 = self.bn3(conv3_2)\n",
    "        relu3_2 = self.relu3(bn3_2)\n",
    "\n",
    "        conv3_3 = self.conv3(relu3_2)\n",
    "        bn3_3 = self.bn3(conv3_3)\n",
    "        relu3_3 = self.relu3(bn3_3)\n",
    "\n",
    "        conv3_4 = self.conv3(relu3_3)\n",
    "        bn3_4 = self.bn3(conv3_4)\n",
    "        relu3_4 = self.relu3(bn3_4)\n",
    "\n",
    "        # pool 2\n",
    "        pool2 = self.pool2(relu3_4)\n",
    "        \n",
    "        # conv 4\n",
    "        conv4_1 = self.conv4(pool2)\n",
    "        bn4_1 = self.bn4(conv4_1)\n",
    "        relu4_1 = self.relu4(bn4_1)\n",
    "\n",
    "        conv4_2 = self.conv4(relu4_1)\n",
    "        bn4_2 = self.bn4(conv4_2)\n",
    "        relu4_2 = self.relu4(bn4_2)\n",
    "\n",
    "        conv4_3 = self.conv4(relu4_2)\n",
    "        bn4_3 = self.bn4(conv4_3)\n",
    "        relu4_3 = self.relu4(bn4_3)\n",
    "\n",
    "        conv4_4 = self.conv4(relu4_3)\n",
    "        bn4_4 = self.bn4(conv4_4)\n",
    "        relu4_4 = self.relu4(bn4_4)\n",
    "\n",
    "        # pool 3\n",
    "        pool3 = self.pool3(relu4_4)\n",
    "\n",
    "        # conv 5\n",
    "        conv5_1 = self.conv5(pool3)\n",
    "        bn5_1 = self.bn5(conv5_1)\n",
    "        relu5_1 = self.relu5(bn5_1)\n",
    "\n",
    "        conv5_2 = self.conv5(relu5_1)\n",
    "        bn5_2 = self.bn5(conv5_2)\n",
    "        relu5_2 = self.relu5(bn5_2)\n",
    "\n",
    "        conv5_3 = self.conv5(relu5_2)\n",
    "        bn5_3 = self.bn5(conv5_3)\n",
    "        relu5_3 = self.relu5(bn5_3)\n",
    "\n",
    "        conv5_4 = self.conv5(relu5_3)\n",
    "        bn5_4 = self.bn5(conv5_4)\n",
    "        relu5_4 = self.relu5(bn5_4)\n",
    "\n",
    "        # pool 4\n",
    "        pool4 = self.pool4(relu5_4)\n",
    "\n",
    "        # fc\n",
    "        flatten = self.flatten(pool4)\n",
    "        fc = self.fc(flatten)\n",
    "\n",
    "        return(fc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slomo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
