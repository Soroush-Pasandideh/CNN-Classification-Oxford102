{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rpWI3cRGPTX"
      },
      "source": [
        "# phase 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0ddSnxuGLAi"
      },
      "source": [
        "## imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSUC7gxINeOx",
        "outputId": "cf2c54f4-c002-49c0-f9ee-0cd07d03b572"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DRxbohbATDdy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from typing import List\n",
        "from torchvision import transforms, models, datasets\n",
        "import torch\n",
        "from torchinfo import summary\n",
        "from torch.utils.data import DataLoader, Subset, random_split, ConcatDataset\n",
        "import numpy as np\n",
        "import random\n",
        "from os.path import exists\n",
        "import os\n",
        "from typing import List, Dict, Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import seaborn as sns\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UkOP_xTGApf"
      },
      "source": [
        "## GPU state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcJYNoSIqHWw",
        "outputId": "78ce5ace-9659-4279-bb17-e995918e65df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "use_gpu = True\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() and use_gpu else \"cpu\")\n",
        "# device = torch.device(\"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GIL20ZmUfhD",
        "outputId": "b167cb4b-2c8b-4d09-f9ca-88d28d3a10d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available:  True\n",
            "Code running on GPU:  True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Check if CUDA (GPU support) is available\n",
        "print(\"CUDA available: \", torch.cuda.is_available())\n",
        "\n",
        "# Check if code is running on GPU\n",
        "print(\"Code running on GPU: \", torch.cuda.is_initialized())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B03Ai5UkTDd0"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "F07yw0wNTDd2"
      },
      "outputs": [],
      "source": [
        "def get_oxford_splits(\n",
        "    batch_size: int,\n",
        "    data_loader_seed: int = 111,\n",
        "    pin_memory: bool = True,\n",
        "    num_workers: int = 2,\n",
        "    ):\n",
        "    K = 5\n",
        "    num_support = 80\n",
        "    num_query = 20\n",
        "\n",
        "    def seed_worker(worker_id):\n",
        "        # worker_seed = torch.initial_seed() % 2 ** 32\n",
        "        np.random.seed(data_loader_seed)\n",
        "        random.seed(data_loader_seed)\n",
        "    g = torch.Generator()\n",
        "    g.manual_seed(data_loader_seed)\n",
        "\n",
        "    support_classes = list(np.arange(num_support))\n",
        "    query_classes = list(np.arange(num_query) + num_support)\n",
        "\n",
        "    img_dim = 64\n",
        "\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.Resize((img_dim, img_dim)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
        "    test_transforms = transforms.Compose([\n",
        "        transforms.Resize((img_dim, img_dim)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
        "    validation_transforms = transforms.Compose([\n",
        "        transforms.Resize((img_dim, img_dim)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
        "\n",
        "    data_path = f'/content/data'\n",
        "\n",
        "    train_ds_full = datasets.Flowers102(root=data_path, split=\"train\", download=True, transform=train_transforms)\n",
        "    val_ds_full = datasets.Flowers102(root=data_path, split=\"val\", download=True, transform=validation_transforms)\n",
        "    test_ds_full = datasets.Flowers102(root=data_path, split=\"test\", download=True, transform=test_transforms)\n",
        "\n",
        "    train_indxs_support = torch.where(torch.isin(torch.tensor(train_ds_full._labels), torch.asarray(support_classes)))[0]\n",
        "    val_indxs_support = torch.where(torch.isin(torch.tensor(val_ds_full._labels), torch.asarray(support_classes)))[0]\n",
        "    test_indxs_support = torch.where(torch.isin(torch.tensor(test_ds_full._labels), torch.asarray(support_classes)))[0]\n",
        "\n",
        "    train_ds_subset_support = torch.utils.data.Subset(train_ds_full, train_indxs_support)\n",
        "    val_ds_subset_support = torch.utils.data.Subset(val_ds_full, val_indxs_support)\n",
        "    test_ds_subset_support = torch.utils.data.Subset(test_ds_full, test_indxs_support)\n",
        "\n",
        "    merged_dataset = ConcatDataset([train_ds_subset_support, val_ds_subset_support, test_ds_subset_support])\n",
        "    ### A, B\n",
        "    train_ds_support, test_ds_support = torch.utils.data.random_split(merged_dataset, [0.75, 0.25], generator=torch.Generator().manual_seed(42))\n",
        "    ###\n",
        "\n",
        "    train_indxs_query = torch.where(torch.isin(torch.tensor(train_ds_full._labels), torch.asarray(query_classes)))[0]\n",
        "    N = 10\n",
        "    starting_indices = np.arange(0, len(train_indxs_query), N)\n",
        "    train_indxs_query = np.hstack([train_indxs_query[i:i+K] for i in starting_indices if i + K <= len(train_indxs_query)])\n",
        "    ### C\n",
        "    train_ds_query = torch.utils.data.Subset(train_ds_full, train_indxs_query)\n",
        "    ###\n",
        "\n",
        "    val_indxs_query = torch.where(torch.isin(torch.tensor(val_ds_full._labels), torch.asarray(query_classes)))[0]\n",
        "    test_indxs_query = torch.where(torch.isin(torch.tensor(test_ds_full._labels), torch.asarray(query_classes)))[0]\n",
        "    val_ds_subset_query = torch.utils.data.Subset(val_ds_full, val_indxs_query)\n",
        "    test_ds_subset_query = torch.utils.data.Subset(test_ds_full, test_indxs_query)\n",
        "\n",
        "    test_ds_query_full = ConcatDataset([val_ds_subset_query, test_ds_subset_query])\n",
        "    ### D\n",
        "    _, test_ds_query = torch.utils.data.random_split(test_ds_query_full, [0.7, 0.3], generator=torch.Generator().manual_seed(42))\n",
        "    ###\n",
        "\n",
        "    ### E\n",
        "    test_all = ConcatDataset([test_ds_query, test_ds_support])\n",
        "\n",
        "\n",
        "    A_train_dl = DataLoader(\n",
        "        train_ds_support,\n",
        "        batch_size = batch_size,\n",
        "        shuffle=True,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g,\n",
        "        drop_last=False,\n",
        "        pin_memory=pin_memory,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "    A_test_dl = DataLoader(\n",
        "        test_ds_support,\n",
        "        batch_size = batch_size,\n",
        "        shuffle=True,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g,\n",
        "        drop_last=False,\n",
        "        pin_memory=pin_memory,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    B_train_dl = DataLoader(\n",
        "        train_ds_query,\n",
        "        batch_size = batch_size,\n",
        "        shuffle=True,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g,\n",
        "        drop_last=False,\n",
        "        pin_memory=pin_memory,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "    B_test_dl = DataLoader(\n",
        "        test_ds_query,\n",
        "        batch_size = batch_size,\n",
        "        shuffle=True,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g,\n",
        "        drop_last=False,\n",
        "        pin_memory=pin_memory,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "    test_all = DataLoader(\n",
        "        test_all,\n",
        "        batch_size = batch_size,\n",
        "        shuffle=True,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g,\n",
        "        drop_last=False,\n",
        "        pin_memory=pin_memory,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    return A_train_dl, A_test_dl, B_train_dl, B_test_dl, test_all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VoGLQNV0AOX"
      },
      "source": [
        "## Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nqwdU4e3TDd4"
      },
      "outputs": [],
      "source": [
        "A_train_dl, A_test_dl, B_train_dl, B_test_dl, test_all = get_oxford_splits(\n",
        "    batch_size=250,\n",
        "    data_loader_seed=111,\n",
        "    pin_memory=False,\n",
        "    num_workers=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryLMC8ZYnkou"
      },
      "source": [
        "## plot output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ygHE7HptnjQA"
      },
      "outputs": [],
      "source": [
        "def make_dir(dir_name: str):\n",
        "    \"\"\"\n",
        "    creates directory \"dir_name\" if it doesn't exists\n",
        "    \"\"\"\n",
        "    if not os.path.exists(dir_name):\n",
        "        os.makedirs(dir_name)\n",
        "\n",
        "def custom_plot_training_stats(\n",
        "        acc_hist,\n",
        "        loss_hist,\n",
        "        phase_list,\n",
        "        title: str,\n",
        "        dir: str,\n",
        "        name: str = 'acc_loss'):\n",
        "    fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize=[14, 6], dpi=100)\n",
        "\n",
        "    for phase in phase_list:\n",
        "        lowest_loss_x = np.argmin(np.array(loss_hist[phase]))\n",
        "        lowest_loss_y = loss_hist[phase][lowest_loss_x]\n",
        "\n",
        "        ax1.annotate(\"{:.4f}\".format(lowest_loss_y), [lowest_loss_x, lowest_loss_y])\n",
        "        ax1.plot(loss_hist[phase], '-x', label=f'{phase} loss', markevery = [lowest_loss_x])\n",
        "\n",
        "        ax1.set_xlabel(xlabel='epochs')\n",
        "        ax1.set_ylabel(ylabel='loss')\n",
        "\n",
        "        ax1.grid(color = 'green', linestyle = '--', linewidth = 0.5, alpha=0.75)\n",
        "        ax1.legend()\n",
        "        ax1.label_outer()\n",
        "\n",
        "    # acc:\n",
        "    for phase in phase_list:\n",
        "        highest_acc_x = np.argmax(np.array(acc_hist[phase]))\n",
        "        highest_acc_y = acc_hist[phase][highest_acc_x]\n",
        "\n",
        "        ax2.annotate(\"{:.4f}\".format(highest_acc_y), [highest_acc_x, highest_acc_y])\n",
        "        ax2.plot(acc_hist[phase], '-x', label=f'{phase} acc', markevery = [highest_acc_x])\n",
        "\n",
        "        ax2.set_xlabel(xlabel='epochs')\n",
        "        ax2.set_ylabel(ylabel='acc')\n",
        "\n",
        "        ax2.grid(color = 'green', linestyle = '--', linewidth = 0.5, alpha=0.75)\n",
        "        ax2.legend()\n",
        "        #ax2.label_outer()\n",
        "\n",
        "    fig.suptitle(f'{title}')\n",
        "\n",
        "    make_dir(dir)\n",
        "    plt.savefig(f'{dir}/{name}.jpg')\n",
        "    plt.clf()\n",
        "\n",
        "def plot_conf(labels, preds, title, dir_, name):\n",
        "    \"\"\"\n",
        "    labels: an [N, ] array containing true labels for N samples\n",
        "    preds: an [N, ] array containing predications for N samples\n",
        "\n",
        "    saves confusion matrix plot of the given prediction and true labels in 'dir_/name.jpg'\n",
        "    \"\"\"\n",
        "\n",
        "    conf = confusion_matrix(labels, preds)\n",
        "\n",
        "    plt.clf()\n",
        "    cm = conf.astype('float') / conf.sum(axis=1)[:, np.newaxis]\n",
        "    cmap = sns.light_palette(\"navy\", as_cmap=True)\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    sns.heatmap(cm, annot=False, cmap=cmap, fmt=\".2f\", cbar=False)\n",
        "    plt.title(f'{title}')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    make_dir(dir_)\n",
        "    plt.savefig(f'{dir_}/{name}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvgSb4Y8TDd5"
      },
      "source": [
        "## Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf-5RW_2TDd5",
        "outputId": "587ecec7-0a1c-4b3a-e265-23eecefbc19f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4617, 1538, 100, 518)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(A_train_dl.dataset), len(A_test_dl.dataset), len(B_train_dl.dataset), len(B_test_dl.dataset),"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KIrJjCgTDd6",
        "outputId": "75bc3b50-49b5-4c78-de81-4520574b76bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(19, 1, 1, 3)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(A_train_dl), len(B_train_dl), len(B_train_dl), len(B_test_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8htOAGm_sKJ",
        "outputId": "af864479-4b8e-44f6-fd7b-bac62f040b63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 64, 64])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A_train_dl.dataset[0][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfSjAZ5ITDd6",
        "outputId": "b33f82fd-7ed1-430a-978a-5d186c94c4f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data index:  0\n",
            "input:  torch.Size([3, 64, 64]) , type of input:  <class 'torch.Tensor'>\n",
            "target:  46 , type of target:  <class 'int'>\n",
            "data index:  1\n",
            "input:  torch.Size([3, 64, 64]) , type of input:  <class 'torch.Tensor'>\n",
            "target:  54 , type of target:  <class 'int'>\n",
            "data index:  2\n",
            "input:  torch.Size([3, 64, 64]) , type of input:  <class 'torch.Tensor'>\n",
            "target:  17 , type of target:  <class 'int'>\n"
          ]
        }
      ],
      "source": [
        "for data_indx, (input, target) in enumerate(A_train_dl.dataset):\n",
        "    if data_indx < 3:\n",
        "        print('data index: ', data_indx)\n",
        "        print('input: ', input.shape, ', type of input: ', type(input))\n",
        "        print('target: ', target, ', type of target: ', type(target))\n",
        "    else:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8X58_xpiTDd8"
      },
      "source": [
        "## Making network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "7mOnovmoTDd8"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes=80):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        # conv1\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        # conv2\n",
        "        self.conv2_1 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2_1 = nn.BatchNorm2d(64)\n",
        "        self.relu2_1 = nn.ReLU()\n",
        "\n",
        "        self.conv2_2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2_2 = nn.BatchNorm2d(64)\n",
        "        self.relu2_2 = nn.ReLU()\n",
        "\n",
        "        self.conv2_3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2_3 = nn.BatchNorm2d(64)\n",
        "        self.relu2_3 = nn.ReLU()\n",
        "\n",
        "        self.conv2_4 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2_4 = nn.BatchNorm2d(64)\n",
        "        self.relu2_4 = nn.ReLU()\n",
        "\n",
        "        # pool1\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # conv3\n",
        "        self.conv3_1 = nn.Conv2d(64, 96, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3_1 = nn.BatchNorm2d(96)\n",
        "        self.relu3_1 = nn.ReLU()\n",
        "\n",
        "        self.conv3_2 = nn.Conv2d(96, 96, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3_2 = nn.BatchNorm2d(96)\n",
        "        self.relu3_2 = nn.ReLU()\n",
        "\n",
        "        self.conv3_3 = nn.Conv2d(96, 96, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3_3 = nn.BatchNorm2d(96)\n",
        "        self.relu3_3 = nn.ReLU()\n",
        "\n",
        "        self.conv3_4 = nn.Conv2d(96, 96, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3_4 = nn.BatchNorm2d(96)\n",
        "        self.relu3_4 = nn.ReLU()\n",
        "\n",
        "        # pool2\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # conv4\n",
        "        self.conv4_1 = nn.Conv2d(96, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4_1 = nn.BatchNorm2d(128)\n",
        "        self.relu4_1 = nn.ReLU()\n",
        "\n",
        "        self.conv4_2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4_2 = nn.BatchNorm2d(128)\n",
        "        self.relu4_2 = nn.ReLU()\n",
        "\n",
        "        self.conv4_3 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4_3 = nn.BatchNorm2d(128)\n",
        "        self.relu4_3 = nn.ReLU()\n",
        "\n",
        "        self.conv4_4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4_4 = nn.BatchNorm2d(128)\n",
        "        self.relu4_4 = nn.ReLU()\n",
        "\n",
        "        # pool3\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # conv5\n",
        "        self.conv5_1 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn5_1 = nn.BatchNorm2d(256)\n",
        "        self.relu5_1 = nn.ReLU()\n",
        "\n",
        "        self.conv5_2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn5_2 = nn.BatchNorm2d(256)\n",
        "        self.relu5_2 = nn.ReLU()\n",
        "\n",
        "        self.conv5_3 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn5_3 = nn.BatchNorm2d(256)\n",
        "        self.relu5_3 = nn.ReLU()\n",
        "\n",
        "        self.conv5_4 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn5_4 = nn.BatchNorm2d(256)\n",
        "        self.relu5_4 = nn.ReLU()\n",
        "\n",
        "        # pool4\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # foolly connected\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(256*4*4, num_classes)\n",
        "\n",
        "    def forward(self, inputs, debug=False):\n",
        "        # conv 1\n",
        "        conv1 = self.conv1(inputs)\n",
        "        bn1 = self.bn1(conv1)\n",
        "        relu1 = self.relu1(bn1)\n",
        "\n",
        "        # conv 2\n",
        "        conv2_1 = self.conv2_1(relu1)\n",
        "        bn2_1 = self.bn2_1(conv2_1)\n",
        "        relu2_1 = self.relu2_1(bn2_1)\n",
        "\n",
        "        conv2_2 = self.conv2_2(relu2_1)\n",
        "        bn2_2 = self.bn2_2(conv2_2)\n",
        "        relu2_2 = self.relu2_2(bn2_2)\n",
        "\n",
        "        conv2_3 = self.conv2_3(relu2_2)\n",
        "        bn2_3 = self.bn2_3(conv2_3)\n",
        "        relu2_3 = self.relu2_3(bn2_3)\n",
        "\n",
        "        conv2_4 = self.conv2_4(relu2_3)\n",
        "        bn2_4 = self.bn2_4(conv2_4)\n",
        "        relu2_4 = self.relu2_4(bn2_4)\n",
        "\n",
        "        # pool 1\n",
        "        pool1 = self.pool1(relu2_4)\n",
        "\n",
        "        # conv 3\n",
        "        conv3_1 = self.conv3_1(pool1)\n",
        "        bn3_1 = self.bn3_1(conv3_1)\n",
        "        relu3_1 = self.relu3_1(bn3_1)\n",
        "\n",
        "        conv3_2 = self.conv3_2(relu3_1)\n",
        "        bn3_2 = self.bn3_2(conv3_2)\n",
        "        relu3_2 = self.relu3_2(bn3_2)\n",
        "\n",
        "        conv3_3 = self.conv3_3(relu3_2)\n",
        "        bn3_3 = self.bn3_3(conv3_3)\n",
        "        relu3_3 = self.relu3_3(bn3_3)\n",
        "\n",
        "        conv3_4 = self.conv3_4(relu3_3)\n",
        "        bn3_4 = self.bn3_4(conv3_4)\n",
        "        relu3_4 = self.relu3_4(bn3_4)\n",
        "\n",
        "        # pool 2\n",
        "        pool2 = self.pool2(relu3_4)\n",
        "\n",
        "        # conv 4\n",
        "        conv4_1 = self.conv4_1(pool2)\n",
        "        bn4_1 = self.bn4_1(conv4_1)\n",
        "        relu4_1 = self.relu4_1(bn4_1)\n",
        "\n",
        "        conv4_2 = self.conv4_2(relu4_1)\n",
        "        bn4_2 = self.bn4_2(conv4_2)\n",
        "        relu4_2 = self.relu4_2(bn4_2)\n",
        "\n",
        "        conv4_3 = self.conv4_3(relu4_2)\n",
        "        bn4_3 = self.bn4_3(conv4_3)\n",
        "        relu4_3 = self.relu4_3(bn4_3)\n",
        "\n",
        "        conv4_4 = self.conv4_4(relu4_3)\n",
        "        bn4_4 = self.bn4_4(conv4_4)\n",
        "        relu4_4 = self.relu4_4(bn4_4)\n",
        "\n",
        "        # pool 3\n",
        "        pool3 = self.pool3(relu4_4)\n",
        "\n",
        "        # conv 5\n",
        "        conv5_1 = self.conv5_1(pool3)\n",
        "        bn5_1 = self.bn5_1(conv5_1)\n",
        "        relu5_1 = self.relu5_1(bn5_1)\n",
        "\n",
        "        conv5_2 = self.conv5_2(relu5_1)\n",
        "        bn5_2 = self.bn5_2(conv5_2)\n",
        "        relu5_2 = self.relu5_2(bn5_2)\n",
        "\n",
        "        conv5_3 = self.conv5_3(relu5_2)\n",
        "        bn5_3 = self.bn5_3(conv5_3)\n",
        "        relu5_3 = self.relu5_3(bn5_3)\n",
        "\n",
        "        conv5_4 = self.conv5_4(relu5_3)\n",
        "        bn5_4 = self.bn5_4(conv5_4)\n",
        "        relu5_4 = self.relu5_4(bn5_4)\n",
        "\n",
        "        # pool 4\n",
        "        pool4 = self.pool4(relu5_4)\n",
        "\n",
        "        # fc\n",
        "        flatten = self.flatten(pool4)\n",
        "        fc = self.fc(flatten)\n",
        "\n",
        "        return(fc)\n",
        "\n",
        "    def freeze_FC_layer(self):\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in self.fc.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    def freeze_FC_first_80_neurons(self):\n",
        "        for param in self.fc.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Unfreeze the parameters of the last 20 neurons\n",
        "        self.fc.weight.data[80:, :].requires_grad = True\n",
        "        self.fc.bias.data[80:].requires_grad = True\n",
        "\n",
        "    def unfreeze_all_layers(self):\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_GDS8aMyxlJ"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "CgXu7x7bzIJr"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model: nn.Module, optim: torch.optim.Optimizer,\n",
        "                    dataloader: DataLoader, loss_fn):\n",
        "\n",
        "    num_samples = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    running_corrects = 0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch_indx, (inputs, targets) in enumerate(dataloader): # Get a batch of Data\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        outputs = model(inputs) # Forward Pass\n",
        "        loss = loss_fn(outputs, targets) # Compute Loss\n",
        "\n",
        "        loss.backward() # Compute Gradients\n",
        "        optim.step() # Update parameters\n",
        "        optim.zero_grad() # zero the parameter's gradients\n",
        "\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        running_corrects += torch.sum(preds == targets).cpu()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # print(f\"< TRAIN >--< {batch_indx} >-------------------------------\")\n",
        "        # print(f\"out:\\n{outputs}\")\n",
        "        # print(f\"tar:\\n{target_tensor}\")\n",
        "        # print(f\"running_corrects:\\n{running_corrects}\")\n",
        "        # print(f\"running_loss:\\n{running_loss}\")\n",
        "\n",
        "    epoch_acc = (running_corrects / num_samples) * 100\n",
        "    print(\"train: \", running_corrects, num_samples)\n",
        "    epoch_loss = (running_loss / num_batches)\n",
        "\n",
        "    return epoch_acc, epoch_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9F2sjhX2e9t"
      },
      "source": [
        "## Test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "pPiBHmCp0jyC"
      },
      "outputs": [],
      "source": [
        "def test_model(model: nn.Module,\n",
        "               dataloader: DataLoader, loss_fn):\n",
        "\n",
        "    num_samples = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    running_corrects = 0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # we call `model.eval()` to set dropout and batch normalization layers to evaluation mode before running inference.\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_indx, (inputs, targets) in enumerate(dataloader): # Get a batch of Data\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            outputs = model(inputs) # Forward Pass\n",
        "            loss = loss_fn(outputs, targets) # Compute Loss\n",
        "\n",
        "            _, preds = torch.max(outputs, 1) #\n",
        "            running_corrects += torch.sum(preds == targets).cpu()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # print(f\"< TEST >--< {batch_indx} >-------------------------------\")\n",
        "            # print(f\"out:\\n{outputs}\")\n",
        "            # print(f\"tar:\\n{target_tensor}\")\n",
        "            # print(f\"running_corrects:\\n{running_corrects}\")\n",
        "            # print(f\"running_loss:\\n{running_loss}\")\n",
        "\n",
        "    test_acc = (running_corrects / num_samples) * 100\n",
        "    print(\"test: \", running_corrects, num_samples)\n",
        "    test_loss = (running_loss / num_batches)\n",
        "\n",
        "    return test_acc, test_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjWz5rRn2jlp"
      },
      "source": [
        "## Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "bAexh8NL1SOm"
      },
      "outputs": [],
      "source": [
        "def evaluate_A():\n",
        "    num_epochs = 30\n",
        "    learning_rate = 0.0005\n",
        "\n",
        "    full_dataloaders = {\n",
        "        'train': A_train_dl,\n",
        "        'test': A_test_dl\n",
        "    }\n",
        "\n",
        "    model = CNN(80)\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    cross_entropy = nn.CrossEntropyLoss()\n",
        "\n",
        "    acc_history = {'train': [], 'test': []}\n",
        "    loss_history = {'train': [], 'test': []}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_acc, train_loss = train_one_epoch(model=model, optim=optimizer, dataloader=full_dataloaders['train'], loss_fn=cross_entropy)\n",
        "        test_acc, test_loss = test_model(model=model, dataloader=full_dataloaders['test'], loss_fn=cross_entropy)\n",
        "\n",
        "        acc_history['train'].append(train_acc)\n",
        "        acc_history['test'].append(test_acc)\n",
        "        loss_history['train'].append(train_loss)\n",
        "        loss_history['test'].append(test_loss)\n",
        "\n",
        "        print(f\"---------< epoch: {epoch} >---------\")\n",
        "\n",
        "    # save model\n",
        "    model_path = './CNN_model_ph1.pth'\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    # plot accuracy and loss\n",
        "    custom_plot_training_stats(acc_history, loss_history, ['train', 'test'], title='demp', dir='demo_plots')\n",
        "\n",
        "    # show the details of model\n",
        "    batch_size=250\n",
        "    print(summary(model, input_size=(batch_size, 3, 64, 64)))\n",
        "\n",
        "    return (acc_history, loss_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3tgjkkym8zzJ",
        "outputId": "8c04e5bf-8f98-44dd-8ab2-4c094914bdf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train:  tensor(395) 4617\n",
            "test:  tensor(60) 1538\n",
            "---------< epoch: 0 >---------\n",
            "train:  tensor(831) 4617\n",
            "test:  tensor(112) 1538\n",
            "---------< epoch: 1 >---------\n",
            "train:  tensor(1297) 4617\n",
            "test:  tensor(412) 1538\n",
            "---------< epoch: 2 >---------\n",
            "train:  tensor(1719) 4617\n",
            "test:  tensor(483) 1538\n",
            "---------< epoch: 3 >---------\n",
            "train:  tensor(2050) 4617\n",
            "test:  tensor(462) 1538\n",
            "---------< epoch: 4 >---------\n",
            "train:  tensor(2328) 4617\n",
            "test:  tensor(625) 1538\n",
            "---------< epoch: 5 >---------\n",
            "train:  tensor(2613) 4617\n",
            "test:  tensor(653) 1538\n",
            "---------< epoch: 6 >---------\n",
            "train:  tensor(2883) 4617\n",
            "test:  tensor(756) 1538\n",
            "---------< epoch: 7 >---------\n",
            "train:  tensor(3061) 4617\n",
            "test:  tensor(784) 1538\n",
            "---------< epoch: 8 >---------\n",
            "train:  tensor(3229) 4617\n",
            "test:  tensor(852) 1538\n",
            "---------< epoch: 9 >---------\n",
            "train:  tensor(3522) 4617\n",
            "test:  tensor(822) 1538\n",
            "---------< epoch: 10 >---------\n",
            "train:  tensor(3647) 4617\n",
            "test:  tensor(861) 1538\n",
            "---------< epoch: 11 >---------\n",
            "train:  tensor(3910) 4617\n",
            "test:  tensor(947) 1538\n",
            "---------< epoch: 12 >---------\n",
            "train:  tensor(4101) 4617\n",
            "test:  tensor(966) 1538\n",
            "---------< epoch: 13 >---------\n",
            "train:  tensor(4211) 4617\n",
            "test:  tensor(968) 1538\n",
            "---------< epoch: 14 >---------\n",
            "train:  tensor(4317) 4617\n",
            "test:  tensor(985) 1538\n",
            "---------< epoch: 15 >---------\n",
            "train:  tensor(4394) 4617\n",
            "test:  tensor(976) 1538\n",
            "---------< epoch: 16 >---------\n",
            "train:  tensor(4458) 4617\n",
            "test:  tensor(935) 1538\n",
            "---------< epoch: 17 >---------\n",
            "train:  tensor(4503) 4617\n",
            "test:  tensor(1023) 1538\n",
            "---------< epoch: 18 >---------\n",
            "train:  tensor(4532) 4617\n",
            "test:  tensor(994) 1538\n",
            "---------< epoch: 19 >---------\n",
            "train:  tensor(4584) 4617\n",
            "test:  tensor(1019) 1538\n",
            "---------< epoch: 20 >---------\n",
            "train:  tensor(4588) 4617\n",
            "test:  tensor(1065) 1538\n",
            "---------< epoch: 21 >---------\n",
            "train:  tensor(4609) 4617\n",
            "test:  tensor(1070) 1538\n",
            "---------< epoch: 22 >---------\n",
            "train:  tensor(4615) 4617\n",
            "test:  tensor(1087) 1538\n",
            "---------< epoch: 23 >---------\n",
            "train:  tensor(4617) 4617\n",
            "test:  tensor(1106) 1538\n",
            "---------< epoch: 24 >---------\n",
            "train:  tensor(4617) 4617\n",
            "test:  tensor(1130) 1538\n",
            "---------< epoch: 25 >---------\n",
            "train:  tensor(4617) 4617\n",
            "test:  tensor(1121) 1538\n",
            "---------< epoch: 26 >---------\n",
            "train:  tensor(4615) 4617\n",
            "test:  tensor(1123) 1538\n",
            "---------< epoch: 27 >---------\n",
            "train:  tensor(4617) 4617\n",
            "test:  tensor(1115) 1538\n",
            "---------< epoch: 28 >---------\n",
            "train:  tensor(4617) 4617\n",
            "test:  tensor(1126) 1538\n",
            "---------< epoch: 29 >---------\n",
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "CNN                                      [250, 80]                 --\n",
            "├─Conv2d: 1-1                            [250, 64, 64, 64]         1,792\n",
            "├─BatchNorm2d: 1-2                       [250, 64, 64, 64]         128\n",
            "├─ReLU: 1-3                              [250, 64, 64, 64]         --\n",
            "├─Conv2d: 1-4                            [250, 64, 64, 64]         36,928\n",
            "├─BatchNorm2d: 1-5                       [250, 64, 64, 64]         128\n",
            "├─ReLU: 1-6                              [250, 64, 64, 64]         --\n",
            "├─Conv2d: 1-7                            [250, 64, 64, 64]         36,928\n",
            "├─BatchNorm2d: 1-8                       [250, 64, 64, 64]         128\n",
            "├─ReLU: 1-9                              [250, 64, 64, 64]         --\n",
            "├─Conv2d: 1-10                           [250, 64, 64, 64]         36,928\n",
            "├─BatchNorm2d: 1-11                      [250, 64, 64, 64]         128\n",
            "├─ReLU: 1-12                             [250, 64, 64, 64]         --\n",
            "├─Conv2d: 1-13                           [250, 64, 64, 64]         36,928\n",
            "├─BatchNorm2d: 1-14                      [250, 64, 64, 64]         128\n",
            "├─ReLU: 1-15                             [250, 64, 64, 64]         --\n",
            "├─MaxPool2d: 1-16                        [250, 64, 32, 32]         --\n",
            "├─Conv2d: 1-17                           [250, 96, 32, 32]         55,392\n",
            "├─BatchNorm2d: 1-18                      [250, 96, 32, 32]         192\n",
            "├─ReLU: 1-19                             [250, 96, 32, 32]         --\n",
            "├─Conv2d: 1-20                           [250, 96, 32, 32]         83,040\n",
            "├─BatchNorm2d: 1-21                      [250, 96, 32, 32]         192\n",
            "├─ReLU: 1-22                             [250, 96, 32, 32]         --\n",
            "├─Conv2d: 1-23                           [250, 96, 32, 32]         83,040\n",
            "├─BatchNorm2d: 1-24                      [250, 96, 32, 32]         192\n",
            "├─ReLU: 1-25                             [250, 96, 32, 32]         --\n",
            "├─Conv2d: 1-26                           [250, 96, 32, 32]         83,040\n",
            "├─BatchNorm2d: 1-27                      [250, 96, 32, 32]         192\n",
            "├─ReLU: 1-28                             [250, 96, 32, 32]         --\n",
            "├─MaxPool2d: 1-29                        [250, 96, 16, 16]         --\n",
            "├─Conv2d: 1-30                           [250, 128, 16, 16]        110,720\n",
            "├─BatchNorm2d: 1-31                      [250, 128, 16, 16]        256\n",
            "├─ReLU: 1-32                             [250, 128, 16, 16]        --\n",
            "├─Conv2d: 1-33                           [250, 128, 16, 16]        147,584\n",
            "├─BatchNorm2d: 1-34                      [250, 128, 16, 16]        256\n",
            "├─ReLU: 1-35                             [250, 128, 16, 16]        --\n",
            "├─Conv2d: 1-36                           [250, 128, 16, 16]        147,584\n",
            "├─BatchNorm2d: 1-37                      [250, 128, 16, 16]        256\n",
            "├─ReLU: 1-38                             [250, 128, 16, 16]        --\n",
            "├─Conv2d: 1-39                           [250, 128, 16, 16]        147,584\n",
            "├─BatchNorm2d: 1-40                      [250, 128, 16, 16]        256\n",
            "├─ReLU: 1-41                             [250, 128, 16, 16]        --\n",
            "├─MaxPool2d: 1-42                        [250, 128, 8, 8]          --\n",
            "├─Conv2d: 1-43                           [250, 256, 8, 8]          295,168\n",
            "├─BatchNorm2d: 1-44                      [250, 256, 8, 8]          512\n",
            "├─ReLU: 1-45                             [250, 256, 8, 8]          --\n",
            "├─Conv2d: 1-46                           [250, 256, 8, 8]          590,080\n",
            "├─BatchNorm2d: 1-47                      [250, 256, 8, 8]          512\n",
            "├─ReLU: 1-48                             [250, 256, 8, 8]          --\n",
            "├─Conv2d: 1-49                           [250, 256, 8, 8]          590,080\n",
            "├─BatchNorm2d: 1-50                      [250, 256, 8, 8]          512\n",
            "├─ReLU: 1-51                             [250, 256, 8, 8]          --\n",
            "├─Conv2d: 1-52                           [250, 256, 8, 8]          590,080\n",
            "├─BatchNorm2d: 1-53                      [250, 256, 8, 8]          512\n",
            "├─ReLU: 1-54                             [250, 256, 8, 8]          --\n",
            "├─MaxPool2d: 1-55                        [250, 256, 4, 4]          --\n",
            "├─Flatten: 1-56                          [250, 4096]               --\n",
            "├─Linear: 1-57                           [250, 80]                 327,760\n",
            "==========================================================================================\n",
            "Total params: 3,405,136\n",
            "Trainable params: 3,405,136\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (G): 299.60\n",
            "==========================================================================================\n",
            "Input size (MB): 12.29\n",
            "Forward/backward pass size (MB): 7602.34\n",
            "Params size (MB): 13.62\n",
            "Estimated Total Size (MB): 7628.24\n",
            "==========================================================================================\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1400x600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "acc_history, loss_history = evaluate_A()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwMi4-EZGXOv"
      },
      "source": [
        "# phase 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JhLLyyXzIsu"
      },
      "source": [
        "## evaluate on B dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "TMUYXvflltgq"
      },
      "outputs": [],
      "source": [
        "def evaluate_B(method: int = 1):\n",
        "    num_epochs = 60\n",
        "    learning_rate = 0.0003\n",
        "\n",
        "\n",
        "    full_dataloaders = {\n",
        "        'train': B_train_dl,\n",
        "        'test': B_test_dl\n",
        "    }\n",
        "\n",
        "    # loading phase1 model\n",
        "    model1 = CNN(80)\n",
        "    model2 = CNN(100)\n",
        "    model1 = model1.to(device)\n",
        "    model2 = model2.to(device)\n",
        "    model_path = './CNN_model_ph1.pth'\n",
        "    model1.load_state_dict(torch.load(model_path))\n",
        "\n",
        "    # Copy parameters from model1 to model2 (excluding the fully connected layer)\n",
        "    for layer1, layer2 in zip(model1.children(), model2.children()):\n",
        "        if isinstance(layer1, nn.Linear):\n",
        "            continue  # Skip copying parameters for fully connected layer\n",
        "\n",
        "        # Copy parameters from layer1 to layer2\n",
        "        for param1, param2 in zip(layer1.parameters(), layer2.parameters()):\n",
        "            param2.data.copy_(param1.data)\n",
        "\n",
        "    model2.fc.weight.data[:80, :] = model1.fc.weight.data\n",
        "    model2.fc.bias.data[:80] = model1.fc.bias.data\n",
        "    # model2.freeze_layers()\n",
        "\n",
        "    optimizer = torch.optim.SGD(model2.parameters(), lr=learning_rate, momentum=0.9)\n",
        "    cross_entropy = nn.CrossEntropyLoss()\n",
        "\n",
        "    acc_history = {'train': [], 'test': []}\n",
        "    loss_history = {'train': [], 'test': []}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_acc, train_loss = train_one_epoch(model=model2, optim=optimizer, dataloader=full_dataloaders['train'], loss_fn=cross_entropy)\n",
        "        test_acc, test_loss = test_model(model=model2, dataloader=full_dataloaders['test'], loss_fn=cross_entropy)\n",
        "\n",
        "        acc_history['train'].append(train_acc)\n",
        "        acc_history['test'].append(test_acc)\n",
        "        loss_history['train'].append(train_loss)\n",
        "        loss_history['test'].append(test_loss)\n",
        "\n",
        "        print(f\"---------< epoch: {epoch} >---------\")\n",
        "\n",
        "    # save model\n",
        "    model_path = './CNN_model_ph2.pth'\n",
        "    torch.save(model2.state_dict(), model_path)\n",
        "\n",
        "    # plot accuracy and loss\n",
        "    custom_plot_training_stats(acc_history, loss_history, ['train', 'test'], title='demp', dir='demo_plots_2')\n",
        "\n",
        "    # show the details of model\n",
        "    batch_size=250\n",
        "    print(summary(model2, input_size=(batch_size, 3, 64, 64)))\n",
        "\n",
        "    return (acc_history, loss_history, model1, model2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aFW6STsOzDFc",
        "outputId": "0f89ed02-475a-4928-94dc-cd120a2e23d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train:  tensor(0) 100\n",
            "test:  tensor(0) 518\n",
            "---------< epoch: 0 >---------\n",
            "train:  tensor(0) 100\n",
            "test:  tensor(0) 518\n",
            "---------< epoch: 1 >---------\n",
            "train:  tensor(0) 100\n",
            "test:  tensor(0) 518\n",
            "---------< epoch: 2 >---------\n",
            "train:  tensor(0) 100\n",
            "test:  tensor(0) 518\n",
            "---------< epoch: 3 >---------\n",
            "train:  tensor(0) 100\n",
            "test:  tensor(0) 518\n",
            "---------< epoch: 4 >---------\n",
            "train:  tensor(0) 100\n",
            "test:  tensor(0) 518\n",
            "---------< epoch: 5 >---------\n",
            "train:  tensor(0) 100\n",
            "test:  tensor(0) 518\n",
            "---------< epoch: 6 >---------\n",
            "train:  tensor(0) 100\n",
            "test:  tensor(0) 518\n",
            "---------< epoch: 7 >---------\n",
            "train:  tensor(0) 100\n",
            "test:  tensor(0) 518\n",
            "---------< epoch: 8 >---------\n",
            "train:  tensor(0) 100\n",
            "test:  tensor(0) 518\n",
            "---------< epoch: 9 >---------\n",
            "train:  tensor(0) 100\n",
            "test:  tensor(0) 518\n",
            "---------< epoch: 10 >---------\n",
            "train:  tensor(0) 100\n",
            "test:  tensor(0) 518\n",
            "---------< epoch: 11 >---------\n",
            "train:  tensor(1) 100\n",
            "test:  tensor(0) 518\n",
            "---------< epoch: 12 >---------\n",
            "train:  tensor(1) 100\n",
            "test:  tensor(0) 518\n",
            "---------< epoch: 13 >---------\n",
            "train:  tensor(1) 100\n",
            "test:  tensor(0) 518\n",
            "---------< epoch: 14 >---------\n",
            "train:  tensor(2) 100\n",
            "test:  tensor(0) 518\n",
            "---------< epoch: 15 >---------\n",
            "train:  tensor(4) 100\n",
            "test:  tensor(0) 518\n",
            "---------< epoch: 16 >---------\n",
            "train:  tensor(6) 100\n",
            "test:  tensor(0) 518\n",
            "---------< epoch: 17 >---------\n",
            "train:  tensor(6) 100\n",
            "test:  tensor(0) 518\n",
            "---------< epoch: 18 >---------\n",
            "train:  tensor(5) 100\n",
            "test:  tensor(0) 518\n",
            "---------< epoch: 19 >---------\n",
            "train:  tensor(10) 100\n",
            "test:  tensor(0) 518\n",
            "---------< epoch: 20 >---------\n",
            "train:  tensor(12) 100\n",
            "test:  tensor(0) 518\n",
            "---------< epoch: 21 >---------\n",
            "train:  tensor(21) 100\n",
            "test:  tensor(0) 518\n",
            "---------< epoch: 22 >---------\n",
            "train:  tensor(19) 100\n",
            "test:  tensor(1) 518\n",
            "---------< epoch: 23 >---------\n",
            "train:  tensor(27) 100\n",
            "test:  tensor(2) 518\n",
            "---------< epoch: 24 >---------\n",
            "train:  tensor(28) 100\n",
            "test:  tensor(3) 518\n",
            "---------< epoch: 25 >---------\n",
            "train:  tensor(37) 100\n",
            "test:  tensor(2) 518\n",
            "---------< epoch: 26 >---------\n",
            "train:  tensor(35) 100\n",
            "test:  tensor(3) 518\n",
            "---------< epoch: 27 >---------\n",
            "train:  tensor(37) 100\n",
            "test:  tensor(5) 518\n",
            "---------< epoch: 28 >---------\n",
            "train:  tensor(40) 100\n",
            "test:  tensor(11) 518\n",
            "---------< epoch: 29 >---------\n",
            "train:  tensor(43) 100\n",
            "test:  tensor(15) 518\n",
            "---------< epoch: 30 >---------\n",
            "train:  tensor(43) 100\n",
            "test:  tensor(18) 518\n",
            "---------< epoch: 31 >---------\n",
            "train:  tensor(53) 100\n",
            "test:  tensor(23) 518\n",
            "---------< epoch: 32 >---------\n",
            "train:  tensor(49) 100\n",
            "test:  tensor(25) 518\n",
            "---------< epoch: 33 >---------\n",
            "train:  tensor(52) 100\n",
            "test:  tensor(35) 518\n",
            "---------< epoch: 34 >---------\n",
            "train:  tensor(52) 100\n",
            "test:  tensor(40) 518\n",
            "---------< epoch: 35 >---------\n",
            "train:  tensor(55) 100\n",
            "test:  tensor(42) 518\n",
            "---------< epoch: 36 >---------\n",
            "train:  tensor(63) 100\n",
            "test:  tensor(46) 518\n",
            "---------< epoch: 37 >---------\n",
            "train:  tensor(64) 100\n",
            "test:  tensor(49) 518\n",
            "---------< epoch: 38 >---------\n",
            "train:  tensor(62) 100\n",
            "test:  tensor(59) 518\n",
            "---------< epoch: 39 >---------\n",
            "train:  tensor(71) 100\n",
            "test:  tensor(68) 518\n",
            "---------< epoch: 40 >---------\n",
            "train:  tensor(68) 100\n",
            "test:  tensor(72) 518\n",
            "---------< epoch: 41 >---------\n",
            "train:  tensor(72) 100\n",
            "test:  tensor(76) 518\n",
            "---------< epoch: 42 >---------\n",
            "train:  tensor(67) 100\n",
            "test:  tensor(82) 518\n",
            "---------< epoch: 43 >---------\n",
            "train:  tensor(74) 100\n",
            "test:  tensor(88) 518\n",
            "---------< epoch: 44 >---------\n",
            "train:  tensor(74) 100\n",
            "test:  tensor(89) 518\n",
            "---------< epoch: 45 >---------\n",
            "train:  tensor(77) 100\n",
            "test:  tensor(96) 518\n",
            "---------< epoch: 46 >---------\n",
            "train:  tensor(78) 100\n",
            "test:  tensor(99) 518\n",
            "---------< epoch: 47 >---------\n",
            "train:  tensor(82) 100\n",
            "test:  tensor(100) 518\n",
            "---------< epoch: 48 >---------\n",
            "train:  tensor(78) 100\n",
            "test:  tensor(102) 518\n",
            "---------< epoch: 49 >---------\n",
            "train:  tensor(81) 100\n",
            "test:  tensor(103) 518\n",
            "---------< epoch: 50 >---------\n",
            "train:  tensor(80) 100\n",
            "test:  tensor(107) 518\n",
            "---------< epoch: 51 >---------\n",
            "train:  tensor(81) 100\n",
            "test:  tensor(109) 518\n",
            "---------< epoch: 52 >---------\n",
            "train:  tensor(84) 100\n",
            "test:  tensor(110) 518\n",
            "---------< epoch: 53 >---------\n",
            "train:  tensor(86) 100\n",
            "test:  tensor(113) 518\n",
            "---------< epoch: 54 >---------\n",
            "train:  tensor(87) 100\n",
            "test:  tensor(114) 518\n",
            "---------< epoch: 55 >---------\n",
            "train:  tensor(90) 100\n",
            "test:  tensor(114) 518\n",
            "---------< epoch: 56 >---------\n",
            "train:  tensor(89) 100\n",
            "test:  tensor(117) 518\n",
            "---------< epoch: 57 >---------\n",
            "train:  tensor(85) 100\n",
            "test:  tensor(119) 518\n",
            "---------< epoch: 58 >---------\n",
            "train:  tensor(90) 100\n",
            "test:  tensor(122) 518\n",
            "---------< epoch: 59 >---------\n",
            "train:  tensor(90) 100\n",
            "test:  tensor(122) 518\n",
            "---------< epoch: 60 >---------\n",
            "train:  tensor(91) 100\n",
            "test:  tensor(123) 518\n",
            "---------< epoch: 61 >---------\n",
            "train:  tensor(91) 100\n",
            "test:  tensor(125) 518\n",
            "---------< epoch: 62 >---------\n",
            "train:  tensor(91) 100\n",
            "test:  tensor(128) 518\n",
            "---------< epoch: 63 >---------\n",
            "train:  tensor(93) 100\n",
            "test:  tensor(133) 518\n",
            "---------< epoch: 64 >---------\n",
            "train:  tensor(93) 100\n",
            "test:  tensor(136) 518\n",
            "---------< epoch: 65 >---------\n",
            "train:  tensor(92) 100\n",
            "test:  tensor(137) 518\n",
            "---------< epoch: 66 >---------\n",
            "train:  tensor(93) 100\n",
            "test:  tensor(140) 518\n",
            "---------< epoch: 67 >---------\n",
            "train:  tensor(94) 100\n",
            "test:  tensor(141) 518\n",
            "---------< epoch: 68 >---------\n",
            "train:  tensor(95) 100\n",
            "test:  tensor(142) 518\n",
            "---------< epoch: 69 >---------\n",
            "train:  tensor(95) 100\n",
            "test:  tensor(143) 518\n",
            "---------< epoch: 70 >---------\n",
            "train:  tensor(98) 100\n",
            "test:  tensor(143) 518\n",
            "---------< epoch: 71 >---------\n",
            "train:  tensor(96) 100\n",
            "test:  tensor(143) 518\n",
            "---------< epoch: 72 >---------\n",
            "train:  tensor(97) 100\n",
            "test:  tensor(145) 518\n",
            "---------< epoch: 73 >---------\n",
            "train:  tensor(96) 100\n",
            "test:  tensor(146) 518\n",
            "---------< epoch: 74 >---------\n",
            "train:  tensor(96) 100\n",
            "test:  tensor(146) 518\n",
            "---------< epoch: 75 >---------\n",
            "train:  tensor(96) 100\n",
            "test:  tensor(148) 518\n",
            "---------< epoch: 76 >---------\n",
            "train:  tensor(96) 100\n",
            "test:  tensor(148) 518\n",
            "---------< epoch: 77 >---------\n",
            "train:  tensor(96) 100\n",
            "test:  tensor(148) 518\n",
            "---------< epoch: 78 >---------\n",
            "train:  tensor(98) 100\n",
            "test:  tensor(151) 518\n",
            "---------< epoch: 79 >---------\n",
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "CNN                                      [250, 100]                --\n",
            "├─Conv2d: 1-1                            [250, 64, 64, 64]         1,792\n",
            "├─BatchNorm2d: 1-2                       [250, 64, 64, 64]         128\n",
            "├─ReLU: 1-3                              [250, 64, 64, 64]         --\n",
            "├─Conv2d: 1-4                            [250, 64, 64, 64]         36,928\n",
            "├─BatchNorm2d: 1-5                       [250, 64, 64, 64]         128\n",
            "├─ReLU: 1-6                              [250, 64, 64, 64]         --\n",
            "├─Conv2d: 1-7                            [250, 64, 64, 64]         36,928\n",
            "├─BatchNorm2d: 1-8                       [250, 64, 64, 64]         128\n",
            "├─ReLU: 1-9                              [250, 64, 64, 64]         --\n",
            "├─Conv2d: 1-10                           [250, 64, 64, 64]         36,928\n",
            "├─BatchNorm2d: 1-11                      [250, 64, 64, 64]         128\n",
            "├─ReLU: 1-12                             [250, 64, 64, 64]         --\n",
            "├─Conv2d: 1-13                           [250, 64, 64, 64]         36,928\n",
            "├─BatchNorm2d: 1-14                      [250, 64, 64, 64]         128\n",
            "├─ReLU: 1-15                             [250, 64, 64, 64]         --\n",
            "├─MaxPool2d: 1-16                        [250, 64, 32, 32]         --\n",
            "├─Conv2d: 1-17                           [250, 96, 32, 32]         55,392\n",
            "├─BatchNorm2d: 1-18                      [250, 96, 32, 32]         192\n",
            "├─ReLU: 1-19                             [250, 96, 32, 32]         --\n",
            "├─Conv2d: 1-20                           [250, 96, 32, 32]         83,040\n",
            "├─BatchNorm2d: 1-21                      [250, 96, 32, 32]         192\n",
            "├─ReLU: 1-22                             [250, 96, 32, 32]         --\n",
            "├─Conv2d: 1-23                           [250, 96, 32, 32]         83,040\n",
            "├─BatchNorm2d: 1-24                      [250, 96, 32, 32]         192\n",
            "├─ReLU: 1-25                             [250, 96, 32, 32]         --\n",
            "├─Conv2d: 1-26                           [250, 96, 32, 32]         83,040\n",
            "├─BatchNorm2d: 1-27                      [250, 96, 32, 32]         192\n",
            "├─ReLU: 1-28                             [250, 96, 32, 32]         --\n",
            "├─MaxPool2d: 1-29                        [250, 96, 16, 16]         --\n",
            "├─Conv2d: 1-30                           [250, 128, 16, 16]        110,720\n",
            "├─BatchNorm2d: 1-31                      [250, 128, 16, 16]        256\n",
            "├─ReLU: 1-32                             [250, 128, 16, 16]        --\n",
            "├─Conv2d: 1-33                           [250, 128, 16, 16]        147,584\n",
            "├─BatchNorm2d: 1-34                      [250, 128, 16, 16]        256\n",
            "├─ReLU: 1-35                             [250, 128, 16, 16]        --\n",
            "├─Conv2d: 1-36                           [250, 128, 16, 16]        147,584\n",
            "├─BatchNorm2d: 1-37                      [250, 128, 16, 16]        256\n",
            "├─ReLU: 1-38                             [250, 128, 16, 16]        --\n",
            "├─Conv2d: 1-39                           [250, 128, 16, 16]        147,584\n",
            "├─BatchNorm2d: 1-40                      [250, 128, 16, 16]        256\n",
            "├─ReLU: 1-41                             [250, 128, 16, 16]        --\n",
            "├─MaxPool2d: 1-42                        [250, 128, 8, 8]          --\n",
            "├─Conv2d: 1-43                           [250, 256, 8, 8]          295,168\n",
            "├─BatchNorm2d: 1-44                      [250, 256, 8, 8]          512\n",
            "├─ReLU: 1-45                             [250, 256, 8, 8]          --\n",
            "├─Conv2d: 1-46                           [250, 256, 8, 8]          590,080\n",
            "├─BatchNorm2d: 1-47                      [250, 256, 8, 8]          512\n",
            "├─ReLU: 1-48                             [250, 256, 8, 8]          --\n",
            "├─Conv2d: 1-49                           [250, 256, 8, 8]          590,080\n",
            "├─BatchNorm2d: 1-50                      [250, 256, 8, 8]          512\n",
            "├─ReLU: 1-51                             [250, 256, 8, 8]          --\n",
            "├─Conv2d: 1-52                           [250, 256, 8, 8]          590,080\n",
            "├─BatchNorm2d: 1-53                      [250, 256, 8, 8]          512\n",
            "├─ReLU: 1-54                             [250, 256, 8, 8]          --\n",
            "├─MaxPool2d: 1-55                        [250, 256, 4, 4]          --\n",
            "├─Flatten: 1-56                          [250, 4096]               --\n",
            "├─Linear: 1-57                           [250, 100]                409,700\n",
            "==========================================================================================\n",
            "Total params: 3,487,076\n",
            "Trainable params: 3,487,076\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (G): 299.62\n",
            "==========================================================================================\n",
            "Input size (MB): 12.29\n",
            "Forward/backward pass size (MB): 7602.38\n",
            "Params size (MB): 13.95\n",
            "Estimated Total Size (MB): 7628.61\n",
            "==========================================================================================\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1400x600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "acc_history2, loss_history2, model1, model2 = evaluate_B()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK9uyBIsAQC0"
      },
      "source": [
        "## check network copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yiMWXgU8is9",
        "outputId": "bd93f6a7-8e13-40a7-f4ed-9262ba886ff1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Are all layers except the fully connected layer equal? True\n",
            "Number of equal parameters in the fully connected layer: 327680\n",
            "Total number of parameters in the fully connected layer: 327680\n",
            "Percentage of equal parameters: 100.00%\n"
          ]
        }
      ],
      "source": [
        "# loading phase1 model\n",
        "model1 = CNN(80)\n",
        "model2 = CNN(100)\n",
        "model1 = model1.to(device)\n",
        "model2 = model2.to(device)\n",
        "model_path = './CNN_model_ph1.pth'\n",
        "model1.load_state_dict(torch.load(model_path))\n",
        "\n",
        "# Copy parameters from model1 to model2 (excluding the fully connected layer)\n",
        "for layer1, layer2 in zip(model1.children(), model2.children()):\n",
        "    if isinstance(layer1, nn.Linear):\n",
        "        continue  # Skip copying parameters for fully connected layer\n",
        "\n",
        "    # Copy parameters from layer1 to layer2\n",
        "    for param1, param2 in zip(layer1.parameters(), layer2.parameters()):\n",
        "        param2.data.copy_(param1.data)\n",
        "\n",
        "model2.fc.weight.data[:80, :] = model1.fc.weight.data\n",
        "model2.fc.bias.data[:80] = model1.fc.bias.data\n",
        "# model2.freeze_layers()\n",
        "\n",
        "# -----------------\n",
        "# Compare all layers except the fully connected layer\n",
        "def are_layers_except_fc_equal(model1, model2):\n",
        "    for layer1, layer2 in zip(model1.children(), model2.children()):\n",
        "        if isinstance(layer1, nn.Linear):\n",
        "            continue  # Skip the fully connected layer\n",
        "        if not all(torch.equal(param1, param2) for param1, param2 in zip(layer1.parameters(), layer2.parameters())):\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "# Check if all layers except the fully connected layer are equal\n",
        "layers_except_fc_equal = are_layers_except_fc_equal(model1, model2)\n",
        "print(f\"Are all layers except the fully connected layer equal? {layers_except_fc_equal}\")\n",
        "\n",
        "# -----------------\n",
        "# Count the number of equal parameters\n",
        "equal_parameters_count = 0\n",
        "total_parameters_count = 0\n",
        "\n",
        "for param1, param2 in zip(model1.fc.weight.data, model2.fc.weight.data):\n",
        "    total_parameters_count += param1.numel()\n",
        "\n",
        "    # Check if parameters are equal\n",
        "    if torch.equal(param1, param2):\n",
        "        equal_parameters_count += param1.numel()\n",
        "\n",
        "# Calculate the percentage of equal parameters\n",
        "percentage_equal_parameters = (equal_parameters_count / total_parameters_count) * 100\n",
        "\n",
        "print(f\"Number of equal parameters in the fully connected layer: {equal_parameters_count}\")\n",
        "print(f\"Total number of parameters in the fully connected layer: {total_parameters_count}\")\n",
        "print(f\"Percentage of equal parameters: {percentage_equal_parameters:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "6VoGLQNV0AOX",
        "cvgSb4Y8TDd5",
        "8X58_xpiTDd8",
        "C9F2sjhX2e9t"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
